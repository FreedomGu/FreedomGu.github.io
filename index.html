<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=â€œwidth=800â€>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
	<style>
        .red-text {
            color: red;
        }
	</style>
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <!--<link rel="icon" type="image/png" href="sjtu_icon.png">-->
  <title>Yuming Gu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Yuming Gu</name>
        </p>
<!--<p class="red-text"> This page is out of date. Please refer to <a href='https://www.yuming-gu.com'> for updates.</a> </p> -->
    <p>I am a PhD Candidate in Computer Science, Viterbi School of Engineering, <a href="https://www.usc.edu">Unviersity of Southern California</a>, advised by <a href='https://stefanosnikolaidis.net/'>Prof. Stefanos Nikolaidis</a>. I also work closely with <a href="https://www.hao-li.com">Prof. Hao Li</a>. Previously I worked at <a href="https://vgl.ict.usc.edu/">Vision and Graphics Lab</a>. 
    <p>My research interests contain Computer Vision and Diffusion Models. In particular, I am interested in using AI-generated content(images and videos) for downstream applications.</p>

        <p align=center>
          <a href="mailto:yuminggu@usc.edu">Email</a> &nbsp/&nbsp
          <a href="./pdf/Yuming_Gu_sCV.pdf">Resume</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=qvciWWMAAAAJ&hl=en">Google Scholar</a>&nbsp/&nbsp
          <a href="https://www.linkedin.com/in/gu-yuming-7a2370153/">Linkedin</a>
        </p>
        </td>
        <td width="33%">
        <img src="buddha.png" width="256">
        </td>
      </tr>
      </table>
      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Education</heading>
          <p>
            <strong>University of Southern California</strong>, USA <br />
            PhD student &bull; Sept. 2022 to Present <br />
            </p>
          <p>
          <strong>University of Southern California</strong>, USA <br />
          Master student &bull; Sept. 2019 to Present <br />
          </p>
          <p>
          <strong>Dalian Maritime University</strong>, China <br />
          Bachelor of Engineering &bull; Sept. 2015 to Jun. 2019 <br />
          </p>
        </td>
      </tr>
      </table> -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading><font color="black">News</font></heading>
            <ul>
              <li>Please reach out if you were interested in collaboration.</li> 
            
              <li>Looking for Industry Internship Opportunities, DM if you were interested! </li>
            </ul>
          </td>
        </tr>
        </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading><font color="black">Professional Services</font></heading>
                <br>
                  Reviewer of the following conferences/journals:
                  <br>
                  <strong> CVPR, ECCV, ICCV, WACV</strong>
                <!-- </ul> -->
              </td>
            </tr>
            </tbody></table>





            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
          
  
              <tr>
                 <td style="padding:20px;width:100%;vertical-align:middle">
                   <heading>Experience</heading>
              <p>
                    <strong>MBZUAI</strong>
                    <br> Abu Dhabi, United Arab Emirates
              <br>Visiting Student, 2024
         <br> 
                   </p>
                   <p>
                    
                    <strong>TikTok</strong>
                    <br> San Jose, United States
              <br>Research Intern, 2023
         <br> 
                   </p>
       
                 </td>
               </tr>
               <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
 
                <tr>
                   <td style="padding:20px;width:100%;vertical-align:middle">
                     <heading>Teaching</heading>
                     <p>
                      Teaching Assistant, CSCI 585 Database Systems
                      <br>
                      Teaching Assistant, CSCI 572 Web Engine
           <br> 
                     </p>
         
                   </td>
                 </tr>
               </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td width="100%" valign="middle">

      <tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
        </td>
      </tr>
      </table>



      


      
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <video id="matting-video" autoplay muted loop playsinline width="450">
          <source src="./DiffPortrait360/Diff360/Teaser_video.mp4"
                  type="video/mp4" >
        </video>
        <!-- <img src='DiffPortrait360/Diff360/Teaser_video.mp4' width="450"> -->
      </td>
      <td valign="top" width="75%">
    <a href="https://freedomgu.github.io/DiffPortrait360/">
            <papertitle>DiffPortrait360: Consistent Portrait Diffusion for 360 View Synthesis</papertitle>
    </a>
    <br>
    <strong>Yuming Gu</strong>, Phong Tran, Yujian Zheng, Hongyi Xu, Heyuan Li, Adilbek Karmanov, Hao Li.<br>
        <em>CVPR</em>, 2025 
        [<a href="">PDF</a>][<a href="https://freedomgu.github.io/DiffPortrait360/">Page</a>][<a href="https://github.com/FreedomGu/DiffPortrait360/">Code</a>]<br>
        <em>Area: Novel View Synthesis, Diffusion Model, Head</em> <br>
        <p> We introduce Diffportrait360, a novel approach generates fully consistent 360-degree head views, accommodating human, stylized, and anthropomorphic forms, including accessories like glasses.</p>
      </td>
    </tr>

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='diffportrait3d_teaser.gif' width="450">
      </td>
      <td valign="top" width="75%">
    <a href="https://freedomgu.github.io/DiffPortrait3D/">
            <papertitle>Diffportrait3d: Controllable diffusion for zero-shot portrait view synthesis</papertitle>
    </a>
    <br>
    <strong>Yuming Gu</strong>, You Xie, Hongyi Xu, Guoxian Song, Yichun Shi, Di Chang, Jing Yang, Linjie Luo.<br>
        <em>CVPR</em>, 2024 <font color="red"><strong>(Highlight - Top 9.3%)</strong></font>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Gu_DiffPortrait3D_Controllable_Diffusion_for_Zero-Shot_Portrait_View_Synthesis_CVPR_2024_paper.pdf">PDF</a>][<a href="https://freedomgu.github.io/DiffPortrait3D/">Page</a>][<a href="https://github.com/FreedomGu/DiffPortrait3D/">Code</a>]<br>
        <em>Area: Novel View Synthesis, Diffusion Model, Face</em> <br>
        <p> We present DiffPortrait3D, a conditional diffusion model
          that is capable of synthesizing 3D-consistent photo-realistic
          novel views from as few as a single in-the-wild portrait.</p>
      </td>
    </tr>

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='ICCV2021.png' width="450">
      </td>
      <td valign="top" width="75%">
    <a href="https://arxiv.org/pdf/2004.12452.pdf">
            <papertitle>DisUnknown: Distilling Unknown Factors for Disentanglement Learning</papertitle>
    </a>
    <br>
    Sitao Xiang, <strong>Yuming Gu</strong>, Pengda Xiang, Menglei Chai, Hao Li, Yajie Zhao, Mingming He<br>
        <em>ICCV</em>, 2021 [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xiang_DisUnknown_Distilling_Unknown_Factors_for_Disentanglement_Learning_ICCV_2021_paper.pdf">PDF</a>]
        [<a href="https://stormraiser.github.io/disunknown/">Page</a>]
        [<a href="https://github.com/stormraiser/disunknown">Code</a>]
         <br>
        <em>Area: Disentanglement, neural feature</em> <br>
        <p> We adopt a general setting where all factors that are hard to label or identify are encapsulated as a single unknown factor.</p>
      </td>
    </tr>

    <!-- <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" align="center">
      <td width="15%">
        <img src='owen.gif' width="300">
      </td>
      <td valign="top" width="75%">
    <a href="https://github.com/FreedomGu/HeadBackReconstruction">
            <papertitle>Light-Stage Head Back Reconstruction</papertitle>
    </a>
    <br> <strong>Yuming Gu</strong><br>
        <em> project </em>, 2020 [<a href="https://github.com/FreedomGu/HeadBackReconstruction">Project Page</a>] <br>
        <em>Area: Graphics, human face</em> <br>
      </td>
    </tr> -->

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='one-shot.gif' width="450">
      </td>
      <td valign="top" width="75%">
    <a href="https://arxiv.org/pdf/2004.12452.pdf">
            <papertitle>One-Shot Identity-Preserving Portrait Reenactment</papertitle>
    </a>
    <br>
    Sitao Xiang, <strong>Yuming Gu</strong>, Pengda Xiang, Mingming He, Koki Nagano, Haiwei Chen, Hao Li<br>
        <em>arixv preprint</em>, 2020 [<a href="https://arxiv.org/pdf/2004.12452.pdf">PDF</a>] <br>
        <em>Area: Image systhesis, human face</em> <br>
        <p>We present a deep learning-based framework for portrait
reenactment from a single picture of a target (one-shot) and a video of a
driving subject.</p>
      </td>
    </tr>
    
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='deepfake.gif'  width="450">
      </td>
      <td valign="top" width="75%">
	  <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Agarwal_Protecting_World_Leaders_Against_Deep_Fakes_CVPRW_2019_paper.pdf">
            <papertitle>Protecting World Leaders Against Deep Fakes</papertitle>
	  </a>
	  <br>
          Shruti Agarwal, Hany Farid, <strong>Yuming Gu</strong>, Mingming He, Koki Nagano,  Hao Li<br>
	      <em>Computer Vision and Pattern Recognition (CVPR workshops)</em>, 2019 [<a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Agarwal_Protecting_World_Leaders_Against_Deep_Fakes_CVPRW_2019_paper.pdf">PDF</a>] <br>
          <em>Area: Image systhesis, Media Forensics</em> <br>
          <p></p>
          <p>we describe a forensic technique that models facial expressions and movements that typify an individual's speaking pattern.</p>
        </td>
    </tr>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          <a href="https://jonbarron.info">Copy this bro...</a>
	    </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/9.js?i=5m6xs1j09rt&amp;t=yuming" async="async"></script>
  </body>
</html>
